# 2019年03月27日 星期三-讨论

## 讨论1：stream group存在意义

### 问题场景：

stream group最初设计思想与Storage group类似，希望用户将同一类别或环境下、经常需要一起处理的流放在一起，可以加速计算，减小开销(如同一个设备的多个传感器要一起计算)。加速原理是将stream group与下层的Storage engine绑定。

但是创建stream 任务的时候需要基于已经存在的时间序列数据，这些时序数据的Storage group已经制定好。同时，并不禁止流框架的任务接收跨Storage group的序列作为输入。如此一来，stream group存在意义基本丧失。

### 讨论结论：

可以不加。



## 讨论2：流框架定位：位于数据处理的哪个阶段？

### 问题场景：

influxdb的流框架Kapacitor支持这样的功能：在数据写入influxdb前会进行降采样等处理，使influxdb可以接收更高频的数据。

但是IoTDB流框架大部分功能处于memory table之后，即从memory table中获取数据，触发操作，再将数据写回到memory table。数据预处理和降采样阶段在memory table之前，有点突兀。

### 讨论结论：

流框架与memory table紧密结合，定位成“memory table接到数据"到“写入磁盘”之间的触发器。所有时间序列都可以设置触发任务。

流框架用到的序列可能因为LRU而移出内存。因此，流框架的数据来源分为两种：1. Memory table，2. 通过查询接口从磁盘中查出。

查询磁盘耗时较大，可以进一步优化memory table，提出"sliding memory"概念，使得memory table可以无缝对接流框架。例如，正在运行的任务降低移除概率，memory table维护的时间序列应大于等于任务指定的window长度等。

## 讨论3：流框架任务的输出去向

参考influxdb，除了写成新的序列，还可以直接输出到https等(Grafana需求)。

## 讨论4： 流框架语言

### 讨论结论：

是否允许用户指定复杂的逻辑任务？

如果否：流框架仅支持已经实现的功能；

如果是：用户可以给予一系列基本算子(如四则运算，以及参考spark-map-reduce和influxdb)，以及"顺序-条件-循环"三大基本逻辑，自由组合任务。

如果是后者，应该调研是否有触发器或存储过程的编译器，避免消耗过多时间在语法解析上。

## 讨论5：流框架如何处理乱序数据和Overflow数据？

### 问题场景：

流框架是否要针对乱序和修改而更新数据？用户可选，例如输出到Grafana的就不允许更新，这是合理的。但强制不允许更新是不协调的，因为流框架如果和BufferWrite紧密结合，那么流框架"触发器"的角色就更突出了。iotdb正常写入数据是允许乱序的，为什么用到触发器会导致数据更新不及时？这有点说不通。

同样的道理，设置"过期时间"，过于乱序的数据不更新到流框架也是不合适的。

**流框架与memory table结合越紧，对于乱序的支持力度就要越大。**

分为三种类型：

1. 尚未推送给流框架是BufferWrite发生修改：对流框架没有影响；
2. 流框架和memory table均已flush出去，出现更新，更新到Overflow中，Overflow在flush的时候，同步触发流框架任务写出即可。这样流框架产生的结果也包括了"正序数据"和"Overflow数据"
3. 流框架已经产生数据，memory table尚未刷出，此时出现了对于memory table的更改(乱序数据到来)，此时没有机制能通知流框架更新结果。

### 讨论结果：

存疑。